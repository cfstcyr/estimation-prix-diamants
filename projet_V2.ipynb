{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302: Méthodes probabilistes et statistiques pour l'I.A.\n",
    "## Projet\n",
    "\n",
    "- Vincent Haney\n",
    "- Félix Pelletier\n",
    "- Charles-François St-Cyr (275354)\n",
    "- Mikael Vaillant (2029994)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\vaill\\.julia\\registries\\General.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\vaill\\.julia\\environments\\v1.8\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\vaill\\.julia\\environments\\v1.8\\Manifest.toml`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "normalize (generic function with 9 methods)"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Pkg;\n",
    "packages = [\"CSV\", \"DataFrames\", \"Distributions\", \"Gadfly\", \"MLBase\", \"Random\", \"Statistics\", \"Colors\", \"GLM\", \"LinearAlgebra\", \"Combinatorics\", \"CategoricalArrays\",\"Distances\",\"NearestNeighbors\"];\n",
    "# peut aps être mis dans une fonction. using doit être top-level\n",
    "for package in packages\n",
    "    try\n",
    "        @eval using $(Symbol(package))\n",
    "    catch e\n",
    "        Pkg.add(package)\n",
    "        @eval using $(Symbol(package))\n",
    "    end\n",
    "end\n",
    "Pkg.update()\n",
    "\n",
    "include(\"./library/main.jl\")\n",
    "include(\"./library/normalize.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données (partiel pour l'exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T13:15:27.338079Z",
     "start_time": "2023-04-04T13:15:15.608008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×10 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">ID</th><th style = \"text-align: left;\">cut</th><th style = \"text-align: left;\">color</th><th style = \"text-align: left;\">clarity</th><th style = \"text-align: left;\">depth</th><th style = \"text-align: left;\">table</th><th style = \"text-align: left;\">price</th><th style = \"text-align: left;\">x</th><th style = \"text-align: left;\">y</th><th style = \"text-align: left;\">z</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Union{Missing, String15}\" style = \"text-align: left;\">String15?</th><th title = \"String1\" style = \"text-align: left;\">String1</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"font-style: italic; text-align: left;\">missing</td><td style = \"text-align: left;\">E</td><td style = \"text-align: left;\">SI2</td><td style = \"text-align: right;\">60.2</td><td style = \"text-align: right;\">60.0</td><td style = \"text-align: right;\">5340</td><td style = \"text-align: right;\">6.46</td><td style = \"text-align: right;\">6.5</td><td style = \"text-align: right;\">3.9</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">4</td><td style = \"text-align: left;\">Ideal</td><td style = \"text-align: left;\">G</td><td style = \"text-align: left;\">VS2</td><td style = \"text-align: right;\">61.7</td><td style = \"text-align: right;\">57.0</td><td style = \"text-align: right;\">720</td><td style = \"text-align: right;\">4.41</td><td style = \"text-align: right;\">4.38</td><td style = \"text-align: right;\">2.71</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">6</td><td style = \"text-align: left;\">Premium</td><td style = \"text-align: left;\">D</td><td style = \"text-align: left;\">VVS2</td><td style = \"text-align: right;\">61.5</td><td style = \"text-align: right;\">60.0</td><td style = \"text-align: right;\">925</td><td style = \"text-align: right;\">4.36</td><td style = \"text-align: right;\">4.42</td><td style = \"text-align: right;\">2.7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">7</td><td style = \"text-align: left;\">Very Good</td><td style = \"text-align: left;\">D</td><td style = \"text-align: left;\">SI1</td><td style = \"text-align: right;\">60.2</td><td style = \"text-align: right;\">61.0</td><td style = \"text-align: right;\">571</td><td style = \"text-align: right;\">4.39</td><td style = \"text-align: right;\">4.42</td><td style = \"text-align: right;\">2.65</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">9</td><td style = \"text-align: left;\">Fair</td><td style = \"text-align: left;\">I</td><td style = \"text-align: left;\">VS1</td><td style = \"text-align: right;\">64.4</td><td style = \"text-align: right;\">59.0</td><td style = \"text-align: right;\">1229</td><td style = \"text-align: right;\">5.3</td><td style = \"text-align: right;\">5.2</td><td style = \"text-align: right;\">3.38</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& ID & cut & color & clarity & depth & table & price & x & y & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String15? & String1 & String7 & Float64? & Float64 & Int64 & Float64 & Float64? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & \\emph{missing} & E & SI2 & 60.2 & 60.0 & 5340 & 6.46 & 6.5 & $\\dots$ \\\\\n",
       "\t2 & 4 & Ideal & G & VS2 & 61.7 & 57.0 & 720 & 4.41 & 4.38 & $\\dots$ \\\\\n",
       "\t3 & 6 & Premium & D & VVS2 & 61.5 & 60.0 & 925 & 4.36 & 4.42 & $\\dots$ \\\\\n",
       "\t4 & 7 & Very Good & D & SI1 & 60.2 & 61.0 & 571 & 4.39 & 4.42 & $\\dots$ \\\\\n",
       "\t5 & 9 & Fair & I & VS1 & 64.4 & 59.0 & 1229 & 5.3 & 5.2 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×10 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ID    \u001b[0m\u001b[1m cut       \u001b[0m\u001b[1m color   \u001b[0m\u001b[1m clarity \u001b[0m\u001b[1m depth    \u001b[0m\u001b[1m table   \u001b[0m\u001b[1m price \u001b[0m\u001b[1m x       \u001b[0m\u001b[1m \u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m String15? \u001b[0m\u001b[90m String1 \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1 \u001b[90m missing   \u001b[0m E        SI2          60.2     60.0   5340     6.46   ⋯\n",
       "   2 │     4  Ideal      G        VS2          61.7     57.0    720     4.41\n",
       "   3 │     6  Premium    D        VVS2         61.5     60.0    925     4.36\n",
       "   4 │     7  Very Good  D        SI1          60.2     61.0    571     4.39\n",
       "   5 │     9  Fair       I        VS1          64.4     59.0   1229     5.3    ⋯\n",
       "\u001b[36m                                                               2 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "test = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "\n",
    "train, valid = partitionData(data, 0.75);\n",
    "\n",
    "first(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(data, x = :price, Geom.histogram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format des données (entrainement et validation): [\"ID\", \"cut\", \"color\", \"clarity\", \"depth\", \"table\", \"price\", \"x\", \"y\", \"z\"]\n",
      "Nombre de valeurs manquantes dans les différentes colonnes: [0, 3806, 0, 0, 2201, 0, 0, 0, 2200, 0]\n",
      "Nombre de valeurs nulles dans les différentes colonnes: [0 0 0 0 13 0 0 4 3 15]\n",
      "Taille de l'ensemble de donnée (entrainement et validation): 40455\n",
      "Format des données test: [\"ID\", \"cut\", \"color\", \"clarity\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
      "Nombre de valeurs manquantes dans les différentes colonnes: [0, 1194, 0, 0, 800, 0, 0, 800, 0]\n",
      "Nombre de valeurs nulles dans l'ensemble test: [0 0 0 0 5 0 4 4 5]\n",
      "Taille de l'ensemble de donnée (test): 13485\n"
     ]
    }
   ],
   "source": [
    "println(\"Format des données (entrainement et validation): \", names(data))\n",
    "\n",
    "missing_counts = collect(count(ismissing,col) for col in eachcol(data))\n",
    "println(\"Nombre de valeurs manquantes dans les différentes colonnes: \", missing_counts)\n",
    "\n",
    "# zero_counts = [count(x -> x == 0, skipmissing(data[:, col])) for col in names(data)]\n",
    "zero_counts = hcat([0,0,0,0]',hcat([count(x -> x < 0.05, skipmissing(data[:, col])) for col in [:depth,:table,:price,:x, :y, :z]]...))\n",
    "\n",
    "println(\"Nombre de valeurs nulles dans les différentes colonnes: \",zero_counts)\n",
    "\n",
    "println(\"Taille de l'ensemble de donnée (entrainement et validation): \",size(data,1))\n",
    "\n",
    "println(\"Format des données test: \", names(test))\n",
    "\n",
    "missing_counts = collect(count(ismissing,col) for col in eachcol(test))\n",
    "println(\"Nombre de valeurs manquantes dans les différentes colonnes: \", missing_counts)\n",
    "\n",
    "zero_counts = hcat([0,0,0,0]',hcat([count(x -> x < 0.05, skipmissing(test[:, col])) for col in [:depth,:table,:x, :y, :z]]...))\n",
    "println(\"Nombre de valeurs nulles dans l'ensemble test: \",zero_counts)\n",
    "\n",
    "println(\"Taille de l'ensemble de donnée (test): \",size(test,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fillDataFromAverage (generic function with 1 method)"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fillDataFromAverage(data::DataFrame; is_test::Bool = false)\n",
    "    avgCut = mode(dropmissing(data, :cut).cut)\n",
    "    avgColor = mode(dropmissing(data, :color).color)\n",
    "    avgClarity = mode(dropmissing(data, :clarity).clarity)\n",
    "    avgDepth = mean(dropmissing(data, :depth).depth)\n",
    "    avgTable = mean(dropmissing(data, :table).table)\n",
    "    avgX = mean(dropmissing(data, :x).x)\n",
    "    avgY = mean(dropmissing(data, :y).y)\n",
    "    avgZ = mean(dropmissing(data, :z).z)\n",
    "    # avgVol = mean(dropmissing(data, :volume).volume)\n",
    "\n",
    "    replace!(data.cut, missing => avgCut)\n",
    "    replace!(data.color, missing => avgColor)\n",
    "    replace!(data.clarity, missing => avgClarity)\n",
    "    replace!(data.depth, missing => avgDepth)\n",
    "    replace!(data.table, missing => avgTable)\n",
    "    replace!(data.x, missing => avgX)\n",
    "    replace!(data.y, missing => avgY)\n",
    "    replace!(data.z, missing => avgZ)\n",
    "    # replace!(data.volume, missing => avgVol)\n",
    "\n",
    "    if (!is_test)\n",
    "        avgPrice = mean(dropmissing(data, :price).price)\n",
    "        replace!(data.price, missing => avgPrice)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES - voici quelques informations importantes découvertes\n",
    "\n",
    "1) enlever les variables depth, table et cut aide à avoir un meilleur RMSE. Peut-être possible de les intégrer en réduisant leur poids? \n",
    "2) Le nombre de voisins peut être ajusté pour obtenir un meilleur RMSE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédictions pour les données pour lesquelles toutes les lignes pleines\n",
    "\n",
    "Plusieurs manipulations sont effectuées sur les matrices pour permettre d'appliquer l'algorithme knn. \n",
    "\n",
    "1. Sélectionner toutes les lignes complètes du DataFrame\n",
    "2. Modifier les valeurs qualitatives en valeurs quantitatives\n",
    "3. Centrer et réduire les colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Manipulations sur le fichier d'entrainement\n",
    "# -------------------------------------------\n",
    "\n",
    "# Copie de train et enregistrement des prix actuel\n",
    "train_ = deepcopy(train)\n",
    "train_ = train_[completecases(train_), :]\n",
    "price_train = select(train_, (:price))\n",
    "\n",
    "# Conversion des colonnes qualitatives en colonnes quantitatives - cut a été enlevé ici\n",
    "convertQualitativeToQuantitative(train_, :color)\n",
    "convertQualitativeToQuantitative(train_, :clarity)\n",
    "\n",
    "# Sélection de toutes les colonnes quantitatives\n",
    "train_no_empty = select(train_, Not([\"price\",\"cut\",\"ID\",\"color\",\"clarity\",\"depth\",\"table\"]))\n",
    "\n",
    "# Normalisation des colonnes de la matrice\n",
    "for col in names(train_no_empty[:,1:end])\n",
    "    train_no_empty[!, col] = (train_no_empty[!, col] .- mean(train_no_empty[!, col])) ./ std(train_no_empty[!, col])\n",
    "end\n",
    "\n",
    "# ------------------------------------------\n",
    "# Manipulations sur le fichier de validation\n",
    "# ------------------------------------------\n",
    "\n",
    "# On sélectionne toutes les données qui possèdent des lignes complètes et qui ne sont pas nulles\n",
    "valid_no_empty = deepcopy(valid)\n",
    "valid_no_empty = valid_no_empty[completecases(valid_no_empty), :]\n",
    "valid_no_empty = valid_no_empty[valid_no_empty.z .>= 0.05, :]\n",
    "\n",
    "test_no_empty = deepcopy(test)\n",
    "test_no_empty = test_no_empty[completecases(test_no_empty), :]\n",
    "test_no_empty = test_no_empty[test_no_empty.z .>= 0.05, :]\n",
    "\n",
    "# Enregistrement du prix actuel et du ID pour le calcul du RMSE \n",
    "price_true_no_empty = select(valid_no_empty, (:price))\n",
    "prediction_no_empty = select(valid_no_empty, (:ID))\n",
    "\n",
    "# price_test_no_empty = select(test_no_empty, (:price))\n",
    "prediction_test_no_empty = select(test_no_empty, (:ID))\n",
    "\n",
    "# Conversion des colonnes qualitatives en colonnes quantitatives - cut a été enlevé ici\n",
    "convertQualitativeToQuantitative(valid_no_empty, :color)\n",
    "convertQualitativeToQuantitative(valid_no_empty, :clarity)\n",
    "\n",
    "convertQualitativeToQuantitative(test_no_empty, :color)\n",
    "convertQualitativeToQuantitative(test_no_empty, :clarity)\n",
    "\n",
    "# Sélection de toutes les colonnes quantitatives\n",
    "valid_no_empty = select(valid_no_empty, Not([\"price\",\"cut\",\"ID\",\"color\",\"clarity\",\"depth\",\"table\"]))\n",
    "\n",
    "test_no_empty = select(test_no_empty, Not([\"cut\",\"ID\",\"color\",\"clarity\",\"depth\",\"table\"]))\n",
    "\n",
    "# Normalisation des colonnes de la matrice\n",
    "for col in names(valid_no_empty[:,1:end])\n",
    "    valid_no_empty[!, col] = (valid_no_empty[!, col] .- mean(valid_no_empty[!, col])) ./ std(valid_no_empty[!, col])\n",
    "end\n",
    "\n",
    "for col in names(test_no_empty[:,1:end])\n",
    "    test_no_empty[!, col] = (test_no_empty[!, col] .- mean(test_no_empty[!, col])) ./ std(test_no_empty[!, col])\n",
    "end\n",
    "\n",
    "# valid_no_empty\n",
    "# valid_y_empty[!, 1:3] = valid_y_empty[!, 1:3].*3\n",
    "# train_y_empty[!, 1:3] = train_y_empty[!, 1:3].*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des données pour le knn\n",
    "Mat_train = Matrix(train_no_empty)'\n",
    "Mat_valid = Matrix(valid_no_empty)'\n",
    "Mat_test = Matrix(test_no_empty)'\n",
    "\n",
    "# Génération de l'arbre de données\n",
    "kdtree = KDTree(Mat_train)\n",
    "\n",
    "# Nombre de plus proches voisins à utiliser\n",
    "k = 5\n",
    "\n",
    "# Algo knn pour valid\n",
    "idxs, dists = knn(kdtree, Mat_valid, k, true)\n",
    "\n",
    "prediction = zeros(size(idxs))\n",
    "for i in 1:size(idxs,1)\n",
    "    prediction[i] =  mean(Matrix(price_train)[idxs[i]])\n",
    "end\n",
    "\n",
    "prediction_no_empty.price = prediction;\n",
    "\n",
    "# Algo knn pour test\n",
    "idxs, dists = knn(kdtree, Mat_test, k, true)\n",
    "\n",
    "prediction = zeros(size(idxs))\n",
    "for i in 1:size(idxs,1)\n",
    "    prediction[i] =  mean(Matrix(price_train)[idxs[i]])\n",
    "end\n",
    "\n",
    "prediction_test_no_empty.price = prediction;\n",
    "\n",
    "# Enregistrement des prédictions de prix avec les IDs pour RMSE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédictions pour les données manquants des valeurs en y et depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Manipulations sur le fichier d'entrainement\n",
    "# -------------------------------------------\n",
    "\n",
    "# Sélection de toutes les colonnes quantitatives\n",
    "train_y_empty = select(train_, Not([\"price\",\"cut\",\"ID\",\"color\",\"clarity\",\"depth\",\"table\",\"y\"]))\n",
    "\n",
    "# Normalisation des colonnes de la matrice\n",
    "for col in names(train_y_empty[:,1:end])\n",
    "    train_y_empty[!, col] = (train_y_empty[!, col] .- mean(train_y_empty[!, col])) ./ std(train_y_empty[!, col])\n",
    "end\n",
    "\n",
    "# ------------------------------------------\n",
    "# Manipulations sur le fichier de validation\n",
    "# ------------------------------------------\n",
    "\n",
    "#En general, y et depth sont manquants en même temps, on va les évaluer en même temps avec les deux colonnes manquantes \n",
    "valid_y_empty = deepcopy(valid)\n",
    "valid_y_empty = valid_y_empty[ismissing.(valid_y_empty[!, \"depth\"]) .| ismissing.(valid_y_empty[!, \"y\"]) .| ismissing.(valid_y_empty[!, \"cut\"]), :]\n",
    "\n",
    "test_y_empty = deepcopy(test)\n",
    "test_y_empty = test_y_empty[ismissing.(test_y_empty[!, \"depth\"]) .| ismissing.(test_y_empty[!, \"y\"]) .| ismissing.(test_y_empty[!, \"cut\"]), :]\n",
    "\n",
    "# Enregistrement du prix actuel et du ID pour le calcul du RMSE \n",
    "price_true_y_empty = select(valid_y_empty, (:price))\n",
    "prediction_y_empty = select(valid_y_empty, (:ID))\n",
    "\n",
    "# price_test_y_empty = select(test_y_empty, (:price))\n",
    "prediction_test_y_empty = select(test_y_empty, (:ID))\n",
    "\n",
    "# Conversion des colonnes qualitatives en colonnes quantitatives - cut a été enlevé ici\n",
    "convertQualitativeToQuantitative(valid_y_empty, :color)\n",
    "convertQualitativeToQuantitative(valid_y_empty, :clarity)\n",
    "\n",
    "convertQualitativeToQuantitative(test_y_empty, :color)\n",
    "convertQualitativeToQuantitative(test_y_empty, :clarity)\n",
    "\n",
    "# Sélection de toutes les colonnes quantitatives\n",
    "valid_y_empty = select(valid_y_empty, Not([\"price\",\"cut\",\"ID\",\"color\",\"clarity\",\"depth\",\"table\",\"y\"]))\n",
    "\n",
    "test_y_empty = select(test_y_empty, Not([\"cut\",\"ID\",\"color\",\"clarity\",\"depth\",\"table\",\"y\"]))\n",
    "\n",
    "# Normalisation des colonnes de la matrice\n",
    "for col in names(valid_y_empty[:,1:end])\n",
    "    valid_y_empty[!, col] = (valid_y_empty[!, col] .- mean(valid_y_empty[!, col])) ./ std(valid_y_empty[!, col])\n",
    "end\n",
    "\n",
    "for col in names(test_y_empty[:,1:end])\n",
    "    test_y_empty[!, col] = (test_y_empty[!, col] .- mean(test_y_empty[!, col])) ./ std(test_y_empty[!, col])\n",
    "end\n",
    "\n",
    "# Changement de poids des différentes variables\n",
    "# valid_y_empty[!, 1:2] = valid_y_empty[!, 1:2].*2\n",
    "# train_y_empty[!, 1:2] = train_y_empty[!, 1:2].*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des données pour le knn\n",
    "Mat_train = Matrix(train_y_empty)'\n",
    "Mat_valid = Matrix(valid_y_empty)'\n",
    "Mat_test = Matrix(test_y_empty)'\n",
    "kdtree = KDTree(Mat_train)\n",
    "\n",
    "# Nombre de plus proches voisins à utiliser\n",
    "k = 5\n",
    "\n",
    "# Algo knn validation\n",
    "idxs, dists = knn(kdtree, Mat_valid, k, true)\n",
    "\n",
    "prediction = zeros(size(idxs))\n",
    "for i in 1:size(idxs,1)\n",
    "    prediction[i] =  mean(Matrix(price_train)[idxs[i]])\n",
    "end\n",
    "\n",
    "# Enregistrement des prédictions de prix avec les IDs pour RMSE\n",
    "prediction_y_empty.price = prediction;\n",
    "\n",
    "# Algo knn test\n",
    "idxs, dists = knn(kdtree, Mat_test, k, true)\n",
    "\n",
    "prediction = zeros(size(idxs))\n",
    "for i in 1:size(idxs,1)\n",
    "    prediction[i] =  mean(Matrix(price_train)[idxs[i]])\n",
    "end\n",
    "\n",
    "# # Enregistrement des prédictions de prix avec les IDs pour RMSE\n",
    "prediction_test_y_empty.price = prediction;\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédictions pour les données nulles et abberrantes\n",
    "\n",
    "En raison du très faible nombre de valeurs nulles ou aberrantes, le prix moyen des diamants a été utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Manipulations sur le fichier de validation\n",
    "# ------------------------------------------\n",
    "\n",
    "#Il n'y a jamais un zéro et des valeurs manquantes\n",
    "valid_0 = deepcopy(valid)\n",
    "valid_0 = valid_0[completecases(valid_0), :]\n",
    "valid_0 = valid_0[valid_0.z .< 0.05, :]\n",
    "\n",
    "test_0 = deepcopy(test)\n",
    "test_0 = test_0[completecases(test_0), :]\n",
    "test_0 = test_0[test_0.z .< 0.05, :]\n",
    "\n",
    "price_true_0 = select(valid_0, (:price))\n",
    "prediction_0 = select(valid_0, (:ID))\n",
    "\n",
    "# price_test_0 = select(test_0, (:price))\n",
    "prediction_test_0 = select(test_0, (:ID))\n",
    "\n",
    "prediction = mean(train[!,\"price\"])\n",
    "\n",
    "prediction_0.price = prediction*ones(size(prediction_0,1))\n",
    "prediction_test_0.price = prediction*ones(size(test_0,1));\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du RMSE pour tous les groupes de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637.1972390014195"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_valid = sort(vcat(prediction_0,prediction_y_empty,prediction_no_empty))[:,\"price\"]\n",
    "\n",
    "# valid\n",
    "RMSE = sqrt(mean((prediction_valid .- valid[:,\"price\"]).^2))\n",
    "\n",
    "# prediction_y_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = sort(vcat(prediction_test_0,prediction_test_y_empty,prediction_test_no_empty))[:,\"price\"]\n",
    "# test.ID\n",
    "CSV.write(\"./results/predictions_knn.csv\", DataFrame(ID = test.ID, price = prediction_test));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ancienne version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train₁ = deepcopy(train)\n",
    "# valid₁ = deepcopy(valid)\n",
    "# valid2 = Matrix(deepcopy(valid))\n",
    "# test₁ = deepcopy(test)\n",
    "\n",
    "# fillDataFromAverage(train₁)\n",
    "# fillDataFromAverage(valid₁)\n",
    "# fillDataFromAverage(test₁, is_test = true)\n",
    "\n",
    "# convertQualitativeToQuantitative(train₁, :color)\n",
    "# # convertQualitativeToQuantitative(train₁, :cut)\n",
    "# convertQualitativeToQuantitative(train₁, :clarity)\n",
    "\n",
    "# convertQualitativeToQuantitative(valid₁, :color)\n",
    "# # convertQualitativeToQuantitative(valid₁, :cut)\n",
    "# convertQualitativeToQuantitative(valid₁, :clarity)\n",
    "\n",
    "# convertQualitativeToQuantitative(test₁, :color)\n",
    "# # convertQualitativeToQuantitative(test₁, :cut)\n",
    "# convertQualitativeToQuantitative(test₁, :clarity)\n",
    "\n",
    "# price_train = select(train₁, (:price))\n",
    "# price_true = select(valid₁, (:price))\n",
    "# test_ids = select(test₁, (:ID))\n",
    "\n",
    "# train₁ = select(train₁, Not([\"price\",\"cut\",\"ID\",\"color\",\"clarity\",\"y\",\"depth\",\"table\"]))\n",
    "# valid₁ = select(valid₁, Not([\"price\",\"cut\",\"ID\",\"color\",\"clarity\",\"y\",\"depth\",\"table\"]))\n",
    "# test₁ = select(test₁, Not([\"cut\",\"ID\",\"color\",\"clarity\",\"y\",\"depth\",\"table\"]))\n",
    "\n",
    "# for col in names(train₁[:,1:3])\n",
    "#     train₁[!, col] = (train₁[!, col] .- mean(train₁[!, col])) ./ std(train₁[!, col])\n",
    "# end\n",
    "\n",
    "# for col in names(valid₁[:,1:3])\n",
    "#     valid₁[!, col] = (valid₁[!, col] .- mean(valid₁[!, col])) ./ std(valid₁[!, col])\n",
    "# end\n",
    "\n",
    "# for col in names(test₁[:,1:3])\n",
    "#     test₁[!, col] = (test₁[!, col] .- mean(test₁[!, col])) ./ std(test₁[!, col])\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "# first(train₁,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mat_train = Matrix(train₁)'\n",
    "# k = 4\n",
    "# Mat_valid = Matrix(valid₁)'\n",
    "\n",
    "# kdtree = KDTree(Mat_train)\n",
    "# idxs, dists = knn(kdtree, Mat_valid, k, true)\n",
    "\n",
    "# prediction = zeros(size(idxs))\n",
    "# for i in 1:size(idxs,1)\n",
    "#     prediction[i] =  mean(Matrix(price_train)[idxs[i]])\n",
    "# end\n",
    "\n",
    "# RMSE = sqrt(mean((prediction .- Matrix(price_true)).^2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afin de vérifier que les plus grosses erreurs ne sont pas provoquées par les valeurs manquantes\n",
    "# On regarde dans le 1/5 des erreurs les plus grande. Si ratio_missing >> 0.2, il y a un problème\n",
    "\n",
    "# err_indivi = sqrt.(((prediction .- Matrix(price_true))[:,1]).^2)\n",
    "# id_err_max = sortperm(err_indivi)[end:-1:1]\n",
    "# data_err_max = valid2[id_err_max[1:div(size(valid2,1),5)],:]\n",
    "\n",
    "# missing_counts1 = collect(count(ismissing,col) for col in eachcol(data_err_max))\n",
    "\n",
    "# missing_counts2 = collect(count(ismissing,col) for col in eachcol(valid2))\n",
    "\n",
    "# ratio_missing = round.([missing_counts1[2],missing_counts1[5],missing_counts1[9]] ./ [missing_counts2[2],missing_counts2[5],missing_counts2[9]],digits=2)\n",
    "\n",
    "# ratio_cut = ratio_missing[1];\n",
    "# ratio_depth = ratio_missing[2];\n",
    "# ratio_y = ratio_missing[3];\n",
    "\n",
    "# println(\"Le ratio de cut dans les 20% d'erreur les plus grandes: $ratio_cut.\")\n",
    "# println(\"Le ratio de depth dans les 20% d'erreur les plus grandes: $ratio_depth.\")\n",
    "# println(\"Le ratio de y dans les 20% d'erreur les plus grandes: $ratio_y.\")\n",
    "\n",
    "#pour le moment, parfaitement distribué, pcq on considère par les colonnes avec des valeurs manquantes, à vérifier une fois que les changements auront été effectués. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afin de vérifier que les plus grosses erreurs ne sont pas provoquées par les valeurs manquantes\n",
    "# On regarde dans le 1/5 des erreurs les plus grande. Si ratio_missing >> 0.2, il y a un problème\n",
    "\n",
    "# num_zeros = count(x -> x == 0, skipmissing(valid2[observation_croiss[1:div(size(valid2,1),10)],:]))\n",
    "# num_zeros2 = count(x -> x == 0, skipmissing(valid2))\n",
    "\n",
    "# ratio_0 = round(num_zeros/num_zeros2,digits=2)\n",
    "# # Print the result\n",
    "# println(\"Le ratio de zéro dans les 10% d'erreur les plus grandes: $ratio_0.\") #67% des zéros sont dans les dix pourcents les plus élevés, il faudra les remplacer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mat_train = Matrix(train₁)'\n",
    "# k = 4\n",
    "# Mat_test = Matrix(test₁)'\n",
    "\n",
    "# kdtree = KDTree(Mat_train)\n",
    "# idxs, dists = knn(kdtree, Mat_test, k, true)\n",
    "\n",
    "# prediction = zeros(size(idxs))\n",
    "# for i in 1:size(idxs,1)\n",
    "#     prediction[i] =  mean(Matrix(price_train)[idxs[i]])\n",
    "# end\n",
    "\n",
    "# CSV.write(\"./results/predictions_knn.csv\", DataFrame(ID = test_ids.ID, price = prediction));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
